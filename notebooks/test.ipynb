{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchmetrics import MeanAbsoluteError, MinMetric, MeanMetric\n",
    "from PIL import Image\n",
    "from xml.etree import ElementTree as ET\n",
    "from typing import Any, Tuple\n",
    "from lightning import LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import torch\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, path, data_dir: str) -> None:\n",
    "        super().__init__()\n",
    "        self.images = ET.parse(path).getroot()[2]\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(244, 244),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Any:\n",
    "        data = self.images[index]\n",
    "        landmarks = []\n",
    "        for landmark in data[0]:\n",
    "            landmarks.append((float(landmark.attrib['x']), float(landmark.attrib['y'])))\n",
    "        transformed = self.transforms(\n",
    "            image=np.array(Image.open(self.data_dir + data.attrib['file']).convert('RGB')), \n",
    "            keypoints=landmarks)\n",
    "        image = transformed['image']\n",
    "        landmarks = torch.tensor(transformed['keypoints']).flatten() / 244\n",
    "        return image, landmarks\n",
    "    \n",
    "class FaceDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_val_split: Tuple[int, int] = (0.8, 0.2),\n",
    "        data_dir: str = \"./data/\",\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_workers = num_workers\n",
    "        self.train_path = data_dir + 'ibug_300W_large_face_landmark_dataset/labels_ibug_300W_train.xml'\n",
    "        self.test_path = data_dir + 'ibug_300W_large_face_landmark_dataset/labels_ibug_300W_test.xml'\n",
    "        train_dataset = FaceDataset(self.train_path, data_dir=data_dir + 'ibug_300W_large_face_landmark_dataset/')\n",
    "        (self.data_train, self.data_val, _) = random_split(\n",
    "            dataset=train_dataset,\n",
    "            lengths=(0.02, 0.02, 0.96),\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "        self.data_test: Dataset = FaceDataset(self.test_path, data_dir=data_dir + 'ibug_300W_large_face_landmark_dataset/')\n",
    "\n",
    "        self.batch_size_per_device = batch_size\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return 136\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader[Any]:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader[Any]:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader[Any]:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "class FaceModule(LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.net = torch.hub.load('pytorch/vision:v0.9.0', 'mobilenet_v2', pretrained=True)\n",
    "        self.net.classifier = torch.nn.Linear(1280, 136)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.metric = MeanAbsoluteError()\n",
    "\n",
    "         # for averaging loss across batches\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.val_loss = MeanMetric()\n",
    "        self.test_loss = MeanMetric()\n",
    "\n",
    "        # for tracking best so far validation accuracy\n",
    "        self.val_loss_best = MinMetric()\n",
    "\n",
    "    def on_train_start(self) -> None:\n",
    "        self.train_loss.reset()\n",
    "        self.val_loss.reset()\n",
    "        self.val_loss_best.reset()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "    \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        # self.train_losses.append(loss.item())\n",
    "        self.train_loss(loss)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        # self.val_losses.append(loss.item())\n",
    "        self.val_loss(loss)\n",
    "        self.log(\"val/loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        # self.test_losses.append(loss.item())\n",
    "        self.test_loss(loss)\n",
    "        self.log(\"test/loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, img: Image) -> Any:\n",
    "        t = A.Compose([\n",
    "            A.Resize(244, 244),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        transformed = t(image=np.array(img))\n",
    "        image = transformed['image']\n",
    "        logits = self.forward(image.unsqueeze(0))\n",
    "        return logits.squeeze(0)\n",
    "\n",
    "    def save_to_state_dict(self, path: str):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_from_state_dict(self, path: str):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceModule()\n",
    "datamodule = FaceDataModule(data_dir='../data/', batch_size=16, num_workers=0, train_val_split=(0.8, 0.2))\n",
    "model = FaceModule()\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    callbacks=[EarlyStopping(monitor=\"val/loss\")],\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def draw(image, landmarks):\n",
    "    # draw image and point landmarks\n",
    "    image = image.copy()\n",
    "    for landmark in landmarks:\n",
    "        cv2.circle(image, (landmark[0], landmark[1]), 1, (0, 255, 0), 3)\n",
    "    plt.imshow(image)\n",
    "    \n",
    "\n",
    "img = Image.open('../data/ibug_300W_large_face_landmark_dataset/ibug/image_003_1.jpg')\n",
    "\n",
    "landmarks = model.predict_step(img=img)\n",
    "landmarks = landmarks.detach().numpy().reshape((68, 2)) * np.array([img.width, img.height])\n",
    "landmarks = landmarks.astype(int)\n",
    "\n",
    "draw(np.array(img), landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
